{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Mount GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FoGy3ROL4kW",
        "outputId": "13f504f1-f95c-45d8-a54b-5f4c0de7ab28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "Q71hgmhfKcJf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jx7o1QTaKDvK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel as parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data \n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Dataset"
      ],
      "metadata": {
        "id": "tWUOE8XaKje8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('drive/MyDrive/ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')"
      ],
      "metadata": {
        "id": "yV0qAO_EKZwU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = pd.read_csv('drive/MyDrive/ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')"
      ],
      "metadata": {
        "id": "Aq1fiUm9LSSD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('drive/MyDrive/ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')"
      ],
      "metadata": {
        "id": "CEnEcreGLTuZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the Training and Test Set"
      ],
      "metadata": {
        "id": "a8Grvv0SUihT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('drive/MyDrive/ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('drive/MyDrive/ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "metadata": {
        "id": "SB2JN8C_Maty"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the number of users and movies"
      ],
      "metadata": {
        "id": "nLtI-fbrLWZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " total_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        " total_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        " print(\"total users: \", total_users)\n",
        " print(\"total movies: \", total_movies)"
      ],
      "metadata": {
        "id": "oQSnwzszVOkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4203f375-4401-4fc7-cc30-b0d331c4fa6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total users:  943\n",
            "total movies:  1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Converting the data into an array with users in lines and movies in columns"
      ],
      "metadata": {
        "id": "Io6JkJ41M7I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(dataset):\n",
        "  user_movies = []\n",
        "  for user_id in range(1,total_users + 1):\n",
        "    movie_ids = dataset[:,1][dataset[:,0] == user_id]\n",
        "    rating_ids = dataset[:,2][dataset[:,0] == user_id]\n",
        "    rating_list = np.zeros(total_movies)\n",
        "    rating_list[movie_ids - 1] = rating_ids\n",
        "    user_movies.append(list(rating_list))\n",
        "  return user_movies"
      ],
      "metadata": {
        "id": "VE7bU6BSMd6i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "6ZvafGpjPx-k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert the data into Torch tensors"
      ],
      "metadata": {
        "id": "EeZmHgzcQwn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "oToAS6X4QCOe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert the ratings into binary ratings"
      ],
      "metadata": {
        "id": "SEUl0qOjXrBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[training_set == 0] = -1 #ratings 0 are invalid\n",
        "#rating 1 or 2 are not liked, hence 0\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set > 2] = 1"
      ],
      "metadata": {
        "id": "RjoKPfnsUpvA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[test_set == 0] = -1 #ratings 0 are invalid\n",
        "#rating 1 or 2 are not liked, hence 0\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set > 2] = 1"
      ],
      "metadata": {
        "id": "7CT66fbtY9w6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the architecture of Neural Network"
      ],
      "metadata": {
        "id": "7eR_pVAkaGbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM:\n",
        "  def __init__(self, no_visibleNodes, no_hiddenNodes):\n",
        "    self.weights = torch.randn(no_hiddenNodes, no_visibleNodes)\n",
        "    self.bias_h = torch.randn(1, no_hiddenNodes)\n",
        "    self.bias_v = torch.randn(1, no_visibleNodes)\n",
        "  \n",
        "  def sample_hidden(self, x):\n",
        "    wx = torch.mm(x, self.weights.t())\n",
        "    activation = wx + self.bias_h.expand_as(wx)\n",
        "    probability_activated_hidden_given_visible = torch.sigmoid(activation)\n",
        "    return probability_activated_hidden_given_visible, torch.bernoulli(probability_activated_hidden_given_visible)\n",
        "  \n",
        "  def sample_visible(self, y):\n",
        "    wy = torch.mm(y, self.weights)\n",
        "    activation = wy + self.bias_v.expand_as(wy)\n",
        "    probability_activated_visible_given_hidden = torch.sigmoid(activation)\n",
        "    return probability_activated_visible_given_hidden, torch.bernoulli(probability_activated_visible_given_hidden)\n",
        "  \n",
        "  def train(self, visible_0, visible_k, probability_hidden_0, probability_hidden_k):\n",
        "    v0 = torch.mm(visible_0.t(), probability_hidden_0)\n",
        "    vk = torch.mm(visible_k.t(), probability_hidden_k)\n",
        "    # self.weights += (v0-vk)\n",
        "    self.bias_v += torch.sum((visible_0-visible_k), 0)\n",
        "    self.bias_h += torch.sum((probability_hidden_0 - probability_hidden_k), 0)"
      ],
      "metadata": {
        "id": "m_VCtZMkZKhT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_visibleNodes = len(training_set[0])\n",
        "no_hiddenNodes = 100\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "p07j32ZQeVJH"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbm = RBM(no_visibleNodes, no_hiddenNodes)"
      ],
      "metadata": {
        "id": "WbT24yWNVz4A"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training the RBM"
      ],
      "metadata": {
        "id": "zdz52WzZWadU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 \n",
        "for e in range(1, epochs+1):\n",
        "  train_loss = 0 \n",
        "  counter = 0.\n",
        "  \n",
        "  for user_id in range(0, total_users - batch_size, batch_size):\n",
        "    visible_k = training_set[user_id: user_id + batch_size]\n",
        "    visible_0 = training_set[user_id: user_id + batch_size]\n",
        "    probability_hidden_0,_ = rbm.sample_hidden(visible_0) #here '_' is used to make all other returned elements as None except probability_hidden_0\n",
        "    \n",
        "    for k in range(10):\n",
        "      _,probability_hidden_k = rbm.sample_hidden(visible_k)\n",
        "      _,visible_k = rbm.sample_visible(probability_hidden_k)\n",
        "      visible_k[visible_0 < 0] = visible_0[visible_0 < 0]\n",
        "    \n",
        "    probability_hidden_k,_ = rbm.sample_hidden(visible_k)\n",
        "    \n",
        "    \n",
        "    rbm.train(visible_0, visible_k, probability_hidden_0, probability_hidden_k)\n",
        "    train_loss += torch.mean(torch.abs(visible_k[visible_0 >= 0] - visible_0[visible_0 >= 0]))\n",
        "    counter += 1.\n",
        "  \n",
        "  print('epoch: ' + str(e) + ' loss: ' + str(train_loss/counter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSWVFOfmWVWD",
        "outputId": "a32c5cab-e3fc-4584-ca5b-1962ace5adef"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.2951)\n",
            "epoch: 2 loss: tensor(0.2511)\n",
            "epoch: 3 loss: tensor(0.2525)\n",
            "epoch: 4 loss: tensor(0.2484)\n",
            "epoch: 5 loss: tensor(0.2492)\n",
            "epoch: 6 loss: tensor(0.2473)\n",
            "epoch: 7 loss: tensor(0.2478)\n",
            "epoch: 8 loss: tensor(0.2496)\n",
            "epoch: 9 loss: tensor(0.2476)\n",
            "epoch: 10 loss: tensor(0.2507)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing the RBM"
      ],
      "metadata": {
        "id": "N8vZvks6gHdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0 \n",
        "counter = 0.\n",
        "\n",
        "for user_id in range(total_users):\n",
        "  visible = training_set[user_id: user_id + 1]\n",
        "  visible_t = test_set[user_id: user_id + 1]\n",
        "  \n",
        "  if len(visible_t[visible_t>=0]) > 0:\n",
        "    _,hidden = rbm.sample_hidden(visible)\n",
        "    _,visible = rbm.sample_visible(hidden)\n",
        "  \n",
        "    test_loss += torch.mean(torch.abs(visible_t[visible_t >= 0] - visible[visible_t >= 0]))\n",
        "    counter += 1.\n",
        "\n",
        "print('test loss: ' + str(test_loss/counter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwS3f3wGbI6-",
        "outputId": "7a2cf00d-df9d-4845-a334-7da9766ecf02"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.2505)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Tq-R470ciNjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}